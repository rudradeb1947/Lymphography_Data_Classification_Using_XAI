# -*- coding: utf-8 -*-
"""Lymphography_Data_Classification_Using_XAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MlT5ujphJJjdwM6TTdIAqBw-8XceZfRh
"""

!pip install shap

##importing libraries##
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy.io as sio
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.metrics import accuracy_score,classification_report
from imblearn.over_sampling import ADASYN
from collections import Counter
import seaborn as sns
import shap

###Data Fetching###
lymph_file="/content/lymph_dataset.mat"
lymph_data=sio.loadmat(lymph_file)
print(lymph_data)
X_raw=lymph_data['norm_data']
y_raw=lymph_data['target']
print(X_raw.shape)
print(y_raw.shape)
Y=np.ravel(y_raw)

###balancing the dataset###
counter=Counter(Y)
print("before",counter)

ada=ADASYN(n_neighbors=1)
X_resamp,Y_resamp=ada.fit_resample(X_raw,Y)

new_counter=Counter(Y_resamp)
print("after",new_counter)

##data normalizing##
scaler=MinMaxScaler()
X=scaler.fit_transform(X_resamp)
print(X)

###Test_Train_Split###
X_train,X_test,Y_train,Y_test=train_test_split(X,Y_resamp,test_size=0.2,random_state=10)
results=[]
train_arr=[]

###Model Calling###
for k in range(1,10):
    clf=KNeighborsClassifier(n_neighbors=k)
    ##training the model.####
    clf.fit(X_train,Y_train)
    train_accuracy=clf.score(X_train,Y_train)
    train_arr.append(train_accuracy)
###Cross_validation accuracy over k neighbours.###
    score=cross_val_score(clf,X_test,Y_test,cv=4)
    results.append(np.mean(score))
print(results)
###training accuracy####
train_accuracy_best=max(train_arr)
train_accuracy_worst=min(train_arr)
print(f"best training accuracy:{train_accuracy_best*100:.2f}%")
print(f"worst training accuracy:{train_accuracy_worst*100:.2f}%")
print(f"mean_traing accuracy:{np.mean(train_arr)*100:.2f}")

###model Graph##
k_list=range(1,10)
sns.lineplot(x=k_list,y=results,marker='o')
plt.ylim(0.4,1.0)
plt.xlabel("k_values")
plt.ylabel("accuracy")
plt.title("Lymphosercoma classifier accuracy")
plt.show()

####model prediction.###
test_pred=clf.predict(X_test)
##classification report.####
accuracy=accuracy_score(Y_test,test_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("\nClassification Report:")
print(classification_report(Y_test,test_pred))
mean= np.mean(results)
Cross_best=max(results)
print(f"Cross_validation best_accuracy:{Cross_best*100:.2f}")
print(f"Cross_validation avarage_accuracy:{mean*100:.2f}")
st_dv=np.std(results)
print(f"Cross _validation standard_deviation:{st_dv*10:.2f}")

import shap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Step 0 — Convert X_test to DataFrame (same as your LIME code)
df_X = pd.DataFrame(X_test)

# Step 1 — Create SHAP KernelExplainer for KNN model
explainer = shap.KernelExplainer(clf.predict_proba, shap.sample(df_X, 100))
# Sample 100 rows as background (adjust if needed)

# Step 2 — Choose an instance to explain (same as LIME)
instance = df_X.iloc[7:16]  # Keep it as DataFrame slice

# Step 3 — Compute SHAP values for the instance (all classes)
shap_values = explainer.shap_values(instance)

# Step 4 — Your class names (same as LIME)
class_names = ['normal find', 'fibrosis', 'metastesis', 'malignant']

# Step 5 — Display explanations (one bar plot per class)
# The shap_values array seems to have an unexpected shape.
# Assuming it's (1, num_features, num_classes), we need to adjust the indexing:
for class_idx, class_label in enumerate(class_names):
    # Accessing SHAP values for the instance, all features, and the current class
    shap_vals_for_class = shap_values[0][:, class_idx]

    feature_names = df_X.columns
    weights = shap_vals_for_class

    # Sort features by absolute SHAP value (optional for clearer plot)
    sorted_idx = np.argsort(np.abs(weights))[::-1]
    feature_names_sorted = feature_names[sorted_idx]
    weights_sorted = weights[sorted_idx]

    # Plot
    plt.figure(figsize=(8, 5))
    plt.bar(feature_names_sorted, weights_sorted, color='red')
    plt.xlabel('Feature')
    plt.ylabel('SHAP Value (Impact)')
    plt.title(f'SHAP Explanation for Class: {class_label}')
    plt.xticks(rotation=90)
    plt.axhline(0, color='black', linewidth=0.7)
    plt.tight_layout()
    plt.show()

